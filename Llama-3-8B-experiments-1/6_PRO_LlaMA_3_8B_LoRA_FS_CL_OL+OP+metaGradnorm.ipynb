{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDH5TQnHabZx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}\")\n",
        "else:\n",
        "  print(\"No GPU detected. Go to Runtime > Change runtime type > GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import of A3CG files\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "print(\"IMPORTING A3CG FILES\")\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive\")\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Drive mounted successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Finding the fold_1 folder\n",
        "print(\"\\nSearching for the 'fold_1' folder...\")\n",
        "\n",
        "possible_path = \"/content/drive/MyDrive/A3CG_Dataset/folds/fold_1\"\n",
        "drive_fold_path = None\n",
        "\n",
        "if os.path.exists(possible_path):\n",
        "    drive_fold_path = possible_path\n",
        "    print(f\"Found: {possible_path}\")\n",
        "else:\n",
        "    print(\"Folder 'fold_1' not found.\")\n",
        "    exit()\n",
        "\n",
        "# List contents of the folder\n",
        "print(f\"\\nContents of: {drive_fold_path}\")\n",
        "files_in_folder = os.listdir(drive_fold_path)\n",
        "required_files = [\"seen_train.json\", \"seen_val.json\", \"seen_test.json\", \"unseen_test.json\"]\n",
        "\n",
        "for file in files_in_folder:\n",
        "    if file.endswith('.json'):\n",
        "        file_path = os.path.join(drive_fold_path, file)\n",
        "        size_kb = os.path.getsize(file_path) / 1024\n",
        "        status = \"[OK]\" if file in required_files else \"[INFO]\"\n",
        "        print(f\"  {status} {file} ({size_kb:.1f} KB)\")\n",
        "\n",
        "# Create local structure\n",
        "local_path = \"/content/A3CG_DATASET/folds/fold_1\"\n",
        "os.makedirs(local_path, exist_ok=True)\n",
        "print(f\"\\nDirectory created: {local_path}\")\n",
        "\n",
        "# Copy files\n",
        "print(\"\\nCopying files...\")\n",
        "copied_count = 0\n",
        "\n",
        "for filename in required_files:\n",
        "    source = os.path.join(drive_fold_path, filename)\n",
        "    dest = os.path.join(local_path, filename)\n",
        "\n",
        "    if os.path.exists(source):\n",
        "        try:\n",
        "            shutil.copy2(source, dest)\n",
        "            size_kb = os.path.getsize(dest) / 1024\n",
        "\n",
        "            # Check for valid JSON\n",
        "            with open(dest, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            print(f\"  [OK] {filename}: {len(data)} samples ({size_kb:.1f} KB)\")\n",
        "            copied_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  [ERROR] {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"  [MISSING] {filename} not found\")\n",
        "\n",
        "# Final result\n",
        "print(f\"\\nRESULT:\")\n",
        "print(f\"  Files copied: {copied_count}/4\")\n",
        "\n",
        "if copied_count >= 3:\n",
        "    print(f\"SUCCESS! Files are ready.\")\n",
        "    print(f\"Path: {local_path}\")\n",
        "\n",
        "    # Show final structure\n",
        "    print(f\"\\nFinal Directory Structure:\")\n",
        "    for root, dirs, files in os.walk(\"/content/A3CG_DATASET\"):\n",
        "        level = root.replace(\"/content/A3CG_DATASET\", '').count(os.sep)\n",
        "        indent = '  ' * level\n",
        "        folder_name = os.path.basename(root) or \"A3CG_DATASET\"\n",
        "        print(f'{indent}- {folder_name}/')\n",
        "\n",
        "        sub_indent = '  ' * (level + 1)\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                size_kb = os.path.getsize(file_path) / 1024\n",
        "                print(f'{sub_indent}- {file} ({size_kb:.1f} KB)')\n",
        "\n",
        "    print(f\"\\nUse this path in your code:\")\n",
        "    print(f\"/content/A3CG_DATASET/folds/fold_1/\")\n",
        "\n",
        "else:\n",
        "    print(f\"FAILURE: Only {copied_count}/4 files were copied.\")\n",
        "    print(\"Please verify that all required JSON files are in your Google Drive folder.\")"
      ],
      "metadata": {
        "id": "U23Mm6K3amLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFace token : get it at https://huggingface.co/settings/tokens\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Interactive login\n",
        "login()\n",
        "\n",
        "# Verification\n",
        "from huggingface_hub import whoami\n",
        "try:\n",
        "    user_info = whoami()\n",
        "    print(f\"Connected as: {user_info['name']}\")\n",
        "except Exception as e:\n",
        "    print(f\"Authentication error: {e}\")"
      ],
      "metadata": {
        "id": "FzcoBpcNamQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================\n",
        "# INSTALLATION SCRIPT\n",
        "# ===================\n",
        "\n",
        "!pip install -q --upgrade transformers peft bitsandbytes accelerate torch datasets scikit-learn \"numpy<2.0\"\n",
        "\n",
        "print(\"Installation completed.\")\n",
        "\n",
        "print(\"Installation successful with compatible versions.\")\n",
        "print(\"\\nNEXT STEPS:\")\n",
        "print(\"1. RESTART THE RUNTIME (MANDATORY)\")\n",
        "print(\"   Runtime > Restart session\")\n",
        "print(\"2. Wait 30 seconds after restart\")\n",
        "\n",
        "print(\"\\nWHY THIS RESTART IS CRITICAL:\")\n",
        "print(\"   - Prevents NumPy 1.x/2.x conflicts in memory\")\n",
        "print(\"   - Clears Python cache\")\n",
        "print(\"   - Ensures correct versions are loaded\")"
      ],
      "metadata": {
        "id": "8TMiIaPHamXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1: DEPENDENCIES INSTALLATION\n",
        "# Run this cell, then manually restart the runtime environment.\n",
        "\n",
        "print(\"STEP 0: Installing and upgrading required packages...\")\n",
        "\n",
        "# Install PyTorch from official CUDA source (cu121) to ensure compatibility and fix torchvision::nms error\n",
        "!pip install -q -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Install other required packages\n",
        "!pip install -q -U transformers peft bitsandbytes accelerate datasets\n",
        "!pip install -q flash-attn --no-build-isolation\n",
        "\n",
        "print(\"\\nINSTALLATION COMPLETE. PLEASE RESTART THE RUNTIME NOW.\")\n",
        "print(\"(Runtime -> Restart session)\")"
      ],
      "metadata": {
        "id": "nI_ofepkambQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LORA + FEW-SHOT + ORDINAL CONTRASTIVE LEARNING WITH GRADNORM META-PARAMETERS\n",
        "\n",
        "# STEP 1: Imports\n",
        "print(\"\\nSTEP 1: Package imports...\")\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, BitsAndBytesConfig, Trainer, TrainerCallback\n",
        "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
        "\n",
        "try:\n",
        "    import bitsandbytes\n",
        "    print(f\"  bitsandbytes: Import OK\")\n",
        "except Exception as e:\n",
        "    print(f\"  bitsandbytes error: {e}\")\n",
        "\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "from datasets import Dataset\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "from collections import Counter\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "\n",
        "# STEP 2: Google Drive mounting\n",
        "print(\"\\nSTEP 2: Google Drive mounting...\")\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"  Drive mounted successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Drive error: {e}\")\n",
        "\n",
        "# STEP 3: Data verification\n",
        "print(\"\\nSTEP 3: Data verification...\")\n",
        "dataset_base = \"/content/A3CG_DATASET/folds/fold_1\"\n",
        "\n",
        "required_files = [\"seen_train.json\", \"seen_val.json\", \"seen_test.json\", \"unseen_test.json\"]\n",
        "files_ok = True\n",
        "\n",
        "for filename in required_files:\n",
        "    filepath = os.path.join(dataset_base, filename)\n",
        "    if os.path.exists(filepath):\n",
        "        size_kb = os.path.getsize(filepath) / 1024\n",
        "        print(f\"  {filename}: {size_kb:.1f} KB\")\n",
        "    else:\n",
        "        print(f\"  {filename}: Missing\")\n",
        "        files_ok = False\n",
        "\n",
        "if not files_ok:\n",
        "    print(\"WARNING: Data files missing!\")\n",
        "    print(\"Run the data import script first\")\n",
        "    exit()\n",
        "\n",
        "# STEP 4: Meta-Parameters Manager\n",
        "print(\"\\nSTEP 4: GradNorm Meta-Parameters Configuration...\")\n",
        "\n",
        "class MetaParametersManager(nn.Module):\n",
        "    \"\"\"Manager for meta-parameters with GradNorm optimization\"\"\"\n",
        "\n",
        "    def __init__(self, initial_lambda_base=0.15, initial_lambda_ord=0.04,\n",
        "                 initial_T_gen=2.5, initial_T_ctr=0.8, epsilon=1e-6):\n",
        "        super().__init__()\n",
        "\n",
        "        def safe_inverse_softplus(x):\n",
        "            return float(np.log(np.exp(float(x)) - 1.0))\n",
        "\n",
        "        # Reparametrized meta-parameters for positivity constraints\n",
        "        self.rho_base = nn.Parameter(\n",
        "            torch.tensor(safe_inverse_softplus(initial_lambda_base - epsilon),\n",
        "                        dtype=torch.float32),\n",
        "            requires_grad=True\n",
        "        )\n",
        "        self.rho_ord = nn.Parameter(\n",
        "            torch.tensor(safe_inverse_softplus(initial_lambda_ord - epsilon),\n",
        "                        dtype=torch.float32),\n",
        "            requires_grad=True\n",
        "        )\n",
        "        self.tau_gen = nn.Parameter(\n",
        "            torch.tensor(safe_inverse_softplus(initial_T_gen - epsilon),\n",
        "                        dtype=torch.float32),\n",
        "            requires_grad=True\n",
        "        )\n",
        "        self.tau_ctr = nn.Parameter(\n",
        "            torch.tensor(safe_inverse_softplus(initial_T_ctr - epsilon),\n",
        "                        dtype=torch.float32),\n",
        "            requires_grad=True\n",
        "        )\n",
        "\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        # Loss tracking for GradNorm\n",
        "        self.loss_history = {'gen': [], 'ctr': [], 'ord': []}\n",
        "        self.initial_losses = {'gen': None, 'ctr': None, 'ord': None}\n",
        "\n",
        "    def get_meta_params(self):\n",
        "        \"\"\"Get actual meta-parameters from reparametrized ones\"\"\"\n",
        "        lambda_base = F.softplus(self.rho_base) + self.epsilon\n",
        "        lambda_ord = F.softplus(self.rho_ord) + self.epsilon\n",
        "        T_gen = F.softplus(self.tau_gen) + self.epsilon\n",
        "        T_ctr = F.softplus(self.tau_ctr) + self.epsilon\n",
        "\n",
        "        return {\n",
        "            'lambda_base': lambda_base,\n",
        "            'lambda_ord': lambda_ord,\n",
        "            'T_gen': T_gen,\n",
        "            'T_ctr': T_ctr\n",
        "        }\n",
        "\n",
        "    def update_loss_history(self, gen_loss, ctr_loss, ord_loss):\n",
        "        \"\"\"Update loss history for GradNorm calculation\"\"\"\n",
        "        def to_float(x):\n",
        "            if isinstance(x, torch.Tensor):\n",
        "                return float(x.detach().cpu().item())\n",
        "            return float(x)\n",
        "\n",
        "        self.loss_history['gen'].append(to_float(gen_loss))\n",
        "        self.loss_history['ctr'].append(to_float(ctr_loss))\n",
        "        self.loss_history['ord'].append(to_float(ord_loss))\n",
        "\n",
        "        # Store initial losses\n",
        "        if self.initial_losses['gen'] is None:\n",
        "            self.initial_losses['gen'] = to_float(gen_loss)\n",
        "            self.initial_losses['ctr'] = to_float(ctr_loss)\n",
        "            self.initial_losses['ord'] = to_float(ord_loss)\n",
        "\n",
        "    def compute_loss_ratios(self, gamma=0.5):\n",
        "        \"\"\"Compute normalized loss ratios for GradNorm\"\"\"\n",
        "        if len(self.loss_history['gen']) == 0:\n",
        "            return {'gen': 1.0, 'ctr': 1.0, 'ord': 1.0}\n",
        "\n",
        "        # Current normalized losses\n",
        "        L_tilde = {}\n",
        "        for k in ['gen', 'ctr', 'ord']:\n",
        "            current_loss = self.loss_history[k][-1]\n",
        "            initial_loss = self.initial_losses[k]\n",
        "            L_tilde[k] = current_loss / (initial_loss + 1e-8)\n",
        "\n",
        "        # Average normalized loss\n",
        "        avg_L_tilde = np.mean(list(L_tilde.values()))\n",
        "\n",
        "        # Loss ratios\n",
        "        ratios = {}\n",
        "        for k in ['gen', 'ctr', 'ord']:\n",
        "            ratios[k] = (L_tilde[k] / (avg_L_tilde + 1e-8)) ** gamma\n",
        "\n",
        "        return ratios\n",
        "\n",
        "print(\"Meta-parameters manager configured\")\n",
        "\n",
        "# STEP 5: Ordinal Contrastive Learning Components\n",
        "print(\"\\nSTEP 5: Ordinal Contrastive Learning Components...\")\n",
        "\n",
        "@dataclass\n",
        "class ContrastiveSample:\n",
        "    \"\"\"Structure for contrastive learning samples\"\"\"\n",
        "    anchor_text: str\n",
        "    anchor_aspects: Dict\n",
        "    positive_text: str\n",
        "    positive_aspects: Dict\n",
        "    negative_text: str\n",
        "    negative_aspects: Dict\n",
        "    anchor_action_type: str = None\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    \"\"\"Standard contrastive loss for aspect-action learning\"\"\"\n",
        "\n",
        "    def __init__(self, temperature: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, anchor_emb, positive_emb, negative_emb, reduction='mean'):\n",
        "        \"\"\"Compute contrastive loss\"\"\"\n",
        "        # Normalize embeddings\n",
        "        anchor_emb = F.normalize(anchor_emb, p=2, dim=1)\n",
        "        positive_emb = F.normalize(positive_emb, p=2, dim=1)\n",
        "        negative_emb = F.normalize(negative_emb, p=2, dim=1)\n",
        "\n",
        "        # Compute similarities\n",
        "        pos_sim = F.cosine_similarity(anchor_emb, positive_emb, dim=1)\n",
        "        neg_sim = F.cosine_similarity(anchor_emb, negative_emb, dim=1)\n",
        "\n",
        "        # Contrastive loss with temperature scaling\n",
        "        pos_exp = torch.exp(pos_sim / self.temperature)\n",
        "        neg_exp = torch.exp(neg_sim / self.temperature)\n",
        "\n",
        "        # InfoNCE-style loss per sample\n",
        "        loss_per_sample = -torch.log(pos_exp / (pos_exp + neg_exp + 1e-8))\n",
        "\n",
        "        if reduction == 'mean':\n",
        "            return loss_per_sample.mean()\n",
        "        elif reduction == 'none':\n",
        "            return loss_per_sample\n",
        "        else:\n",
        "            raise ValueError(f\"reduction must be 'mean' or 'none', got {reduction}\")\n",
        "\n",
        "class OrdinalContrastiveLoss(nn.Module):\n",
        "    \"\"\"Ordinal contrastive loss with asymmetric margins\"\"\"\n",
        "\n",
        "    def __init__(self, base_margin: float = 0.10, planning_margin: float = 0.15):\n",
        "        super().__init__()\n",
        "        self.base_margin = base_margin\n",
        "        self.planning_margin = planning_margin\n",
        "\n",
        "        # Action-to-margin mapping\n",
        "        self.action_margins = {\n",
        "            'implemented': base_margin,\n",
        "            'indeterminate': base_margin,\n",
        "            'planning': planning_margin  # Stricter margin for planning\n",
        "        }\n",
        "\n",
        "    def forward(self, anchor_emb, positive_emb, negative_emb, anchor_actions=None, reduction='mean'):\n",
        "        \"\"\"Compute ordinal contrastive loss with asymmetric margins\"\"\"\n",
        "        # Normalize embeddings\n",
        "        anchor_emb = F.normalize(anchor_emb, p=2, dim=1)\n",
        "        positive_emb = F.normalize(positive_emb, p=2, dim=1)\n",
        "        negative_emb = F.normalize(negative_emb, p=2, dim=1)\n",
        "\n",
        "        # Compute distances (1 - cosine similarity)\n",
        "        distance_0_1 = 1 - F.cosine_similarity(anchor_emb, positive_emb, dim=1)\n",
        "        distance_0_2 = 1 - F.cosine_similarity(anchor_emb, negative_emb, dim=1)\n",
        "\n",
        "        # Determine margins per sample\n",
        "        if anchor_actions is not None:\n",
        "            margins = torch.tensor([\n",
        "                self.action_margins.get(action, self.base_margin)\n",
        "                for action in anchor_actions\n",
        "            ], device=anchor_emb.device, dtype=anchor_emb.dtype)\n",
        "        else:\n",
        "            margins = torch.full((anchor_emb.size(0),), self.base_margin,\n",
        "                               device=anchor_emb.device, dtype=anchor_emb.dtype)\n",
        "\n",
        "        # Ordinal contrastive loss per sample with asymmetric margins\n",
        "        loss_per_sample = F.relu(distance_0_1 - distance_0_2 + margins)\n",
        "\n",
        "        if reduction == 'mean':\n",
        "            return loss_per_sample.mean()\n",
        "        elif reduction == 'none':\n",
        "            return loss_per_sample\n",
        "        else:\n",
        "            raise ValueError(f\"reduction must be 'mean' or 'none', got {reduction}\")\n",
        "\n",
        "class ContrastiveDataGenerator:\n",
        "    \"\"\"Generates ordinal directional contrastive samples for training\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.action_groups = {\n",
        "            'implemented': [],\n",
        "            'planning': [],\n",
        "            'indeterminate': []\n",
        "        }\n",
        "        # Defined ordinal order\n",
        "        self.ordinal_order = ['indeterminate', 'planning', 'implemented']\n",
        "\n",
        "    def group_samples_by_action(self, data: List[Dict]):\n",
        "        \"\"\"Group samples by their predominant action type\"\"\"\n",
        "        for sample in data:\n",
        "            aspects = sample.get('aspects', {})\n",
        "            action_counts = {'implemented': 0, 'planning': 0, 'indeterminate': 0}\n",
        "\n",
        "            for aspect, actions in aspects.items():\n",
        "                for action in actions:\n",
        "                    action_lower = action.lower().strip()\n",
        "                    if action_lower in action_counts:\n",
        "                        action_counts[action_lower] += 1\n",
        "                    else:\n",
        "                        action_counts['indeterminate'] += 1\n",
        "\n",
        "            if sum(action_counts.values()) > 0:\n",
        "                main_action = max(action_counts, key=action_counts.get)\n",
        "                self.action_groups[main_action].append(sample)\n",
        "            else:\n",
        "                self.action_groups['indeterminate'].append(sample)\n",
        "\n",
        "        print(f\" Grouped samples:\")\n",
        "        for action, samples in self.action_groups.items():\n",
        "            print(f\"  {action}: {len(samples)} samples\")\n",
        "\n",
        "    def create_ordinal_directional_pairs(self, data: List[Dict], n_pairs: int = None) -> List[ContrastiveSample]:\n",
        "        \"\"\"Create ORDINAL DIRECTIONAL contrastive pairs with explicit rules\"\"\"\n",
        "        if n_pairs is None:\n",
        "            n_pairs = len(data)\n",
        "\n",
        "        self.group_samples_by_action(data)\n",
        "        contrastive_samples = []\n",
        "\n",
        "        print(f\"  Creating {n_pairs} ORDINAL DIRECTIONAL pairs...\")\n",
        "\n",
        "        # Directional construction rules\n",
        "        ordinal_rules = {\n",
        "            'implemented': {'positive': 'planning', 'negative': 'indeterminate'},\n",
        "            'indeterminate': {'positive': 'planning', 'negative': 'implemented'},\n",
        "            'planning': {'positive': 'implemented', 'negative': 'indeterminate'}\n",
        "        }\n",
        "\n",
        "        for i in range(n_pairs):\n",
        "            if i % 100 == 0:\n",
        "                print(f\" Progress: {i}/{n_pairs}\")\n",
        "\n",
        "            # Select anchor\n",
        "            anchor = random.choice(data)\n",
        "            anchor_aspects = anchor.get('aspects', {})\n",
        "\n",
        "            if not anchor_aspects:\n",
        "                continue\n",
        "\n",
        "            # Determine anchor's main action\n",
        "            anchor_actions = []\n",
        "            for actions in anchor_aspects.values():\n",
        "                anchor_actions.extend([a.lower().strip() for a in actions])\n",
        "\n",
        "            valid_anchor_actions = [a for a in anchor_actions if a in self.ordinal_order]\n",
        "            if not valid_anchor_actions:\n",
        "                anchor_main_action = 'indeterminate'\n",
        "            else:\n",
        "                anchor_main_action = max(set(valid_anchor_actions), key=valid_anchor_actions.count)\n",
        "\n",
        "            # Apply directional ordinal rules\n",
        "            rules = ordinal_rules[anchor_main_action]\n",
        "            positive_action_type = rules['positive']\n",
        "            negative_action_type = rules['negative']\n",
        "\n",
        "            # Find positive and negative candidates\n",
        "            positive_candidates = [s for s in self.action_groups[positive_action_type]\n",
        "                                 if s['text'] != anchor['text']]\n",
        "            negative_candidates = [s for s in self.action_groups[negative_action_type]\n",
        "                                 if s['text'] != anchor['text']]\n",
        "\n",
        "            # Selection with fallback\n",
        "            if positive_candidates:\n",
        "                positive = random.choice(positive_candidates)\n",
        "            else:\n",
        "                other_samples = [s for s in data if s['text'] != anchor['text']]\n",
        "                positive = random.choice(other_samples) if other_samples else anchor\n",
        "\n",
        "            if negative_candidates:\n",
        "                negative = random.choice(negative_candidates)\n",
        "            else:\n",
        "                other_samples = [s for s in data\n",
        "                               if s['text'] != anchor['text'] and s['text'] != positive['text']]\n",
        "                negative = random.choice(other_samples) if other_samples else anchor\n",
        "\n",
        "            contrastive_samples.append(ContrastiveSample(\n",
        "                anchor_text=anchor['text'],\n",
        "                anchor_aspects=anchor_aspects,\n",
        "                positive_text=positive['text'],\n",
        "                positive_aspects=positive.get('aspects', {}),\n",
        "                negative_text=negative['text'],\n",
        "                negative_aspects=negative.get('aspects', {}),\n",
        "                anchor_action_type=anchor_main_action\n",
        "            ))\n",
        "\n",
        "        print(f\"  Generated {len(contrastive_samples)} ORDINAL DIRECTIONAL samples\")\n",
        "        return contrastive_samples\n",
        "\n",
        "print(\"Ordinal Contrastive components configured\")\n",
        "\n",
        "# STEP 6: GradNorm Enhanced Model\n",
        "print(\"\\nSTEP 6: Enhanced model configuration with GradNorm...\")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "print(f\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    padding_side=\"left\"\n",
        ")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(f\"Loading LLaMA-3 model...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={'': 0},\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    attn_implementation=\"flash_attention_2\"\n",
        ")\n",
        "\n",
        "# LoRA preparation\n",
        "base_model = prepare_model_for_kbit_training(base_model)\n",
        "\n",
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.1,\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "\n",
        "class GradNormContrastiveLoRAModel(nn.Module):\n",
        "    \"\"\"Enhanced model with GradNorm meta-parameter optimization\"\"\"\n",
        "\n",
        "    def __init__(self, base_model, hidden_size=4096, contrastive_dim=256):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.contrastive_dim = contrastive_dim\n",
        "\n",
        "        # Contrastive projection head\n",
        "        self.contrastive_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_size // 2, contrastive_dim)\n",
        "        )\n",
        "\n",
        "        # Loss functions\n",
        "        self.contrastive_loss_fn = ContrastiveLoss(temperature=0.1)\n",
        "        self.ordinal_contrastive_loss_fn = OrdinalContrastiveLoss(\n",
        "            base_margin=0.10,\n",
        "            planning_margin=0.15\n",
        "        )\n",
        "\n",
        "        # Meta-parameters manager\n",
        "        self.meta_params = MetaParametersManager()\n",
        "\n",
        "        # Monitoring\n",
        "        self.step_count = 0\n",
        "        self.meta_optimizer = None\n",
        "\n",
        "    def get_text_embedding(self, input_ids, attention_mask):\n",
        "        \"\"\"Extract text embedding for contrastive learning\"\"\"\n",
        "        with torch.no_grad():\n",
        "            outputs = self.base_model.base_model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                output_hidden_states=True\n",
        "            )\n",
        "\n",
        "            last_hidden = outputs.hidden_states[-1]\n",
        "            mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size())\n",
        "            sum_hidden = torch.sum(last_hidden * mask_expanded, dim=1)\n",
        "            sum_mask = torch.sum(mask_expanded, dim=1)\n",
        "            mean_hidden = sum_hidden / sum_mask\n",
        "\n",
        "            return mean_hidden\n",
        "\n",
        "    def compute_component_gradients(self, generation_loss_per_sample, contrastive_loss_per_sample,\n",
        "                                   ordinal_loss_per_sample, meta_params):\n",
        "        \"\"\"Compute gradient norms for each component\"\"\"\n",
        "\n",
        "        lambda_base = meta_params['lambda_base']\n",
        "        lambda_ord = meta_params['lambda_ord']\n",
        "\n",
        "        L_gen = generation_loss_per_sample.mean()\n",
        "        L_ctr = contrastive_loss_per_sample.mean()\n",
        "        L_ord = ordinal_loss_per_sample.mean()\n",
        "\n",
        "        # Get trainable parameters (LoRA + contrastive head)\n",
        "        trainable_params = []\n",
        "\n",
        "        for name, param in self.base_model.named_parameters():\n",
        "            if param.requires_grad and any(lora_key in name.lower() for lora_key in ['lora_a', 'lora_b']):\n",
        "                trainable_params.append(param)\n",
        "\n",
        "        for param in self.contrastive_head.parameters():\n",
        "            if param.requires_grad:\n",
        "                trainable_params.append(param)\n",
        "\n",
        "        if not trainable_params:\n",
        "            device = L_gen.device\n",
        "            return {\n",
        "                'gen': torch.tensor(1.0, device=device, dtype=torch.float32, requires_grad=True),\n",
        "                'ctr': torch.tensor(0.8, device=device, dtype=torch.float32, requires_grad=True),\n",
        "                'ord': torch.tensor(0.6, device=device, dtype=torch.float32, requires_grad=True)\n",
        "            }, L_gen, L_ctr, L_ord\n",
        "\n",
        "        gradients = {}\n",
        "        device = L_gen.device\n",
        "\n",
        "        # Generation gradient\n",
        "        try:\n",
        "            gen_grads = torch.autograd.grad(\n",
        "                outputs=L_gen,\n",
        "                inputs=trainable_params,\n",
        "                retain_graph=True,\n",
        "                create_graph=True,\n",
        "                allow_unused=True\n",
        "            )\n",
        "\n",
        "            grad_squares = [torch.sum(g**2) for g in gen_grads if g is not None]\n",
        "            if grad_squares:\n",
        "                gradients['gen'] = torch.sqrt(torch.stack(grad_squares).sum() + 1e-8)\n",
        "            else:\n",
        "                gradients['gen'] = torch.tensor(1e-3, device=device, dtype=torch.float32, requires_grad=True)\n",
        "        except:\n",
        "            gradients['gen'] = torch.tensor(1e-3, device=device, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "        # Contrastive gradient\n",
        "        try:\n",
        "            if L_ctr.item() > 1e-6:\n",
        "                scaled_ctr_loss = lambda_base * L_ctr\n",
        "                ctr_grads = torch.autograd.grad(\n",
        "                    outputs=scaled_ctr_loss,\n",
        "                    inputs=trainable_params,\n",
        "                    retain_graph=True,\n",
        "                    create_graph=True,\n",
        "                    allow_unused=True\n",
        "                )\n",
        "\n",
        "                grad_squares = [torch.sum(g**2) for g in ctr_grads if g is not None]\n",
        "                if grad_squares:\n",
        "                    gradients['ctr'] = torch.sqrt(torch.stack(grad_squares).sum() + 1e-8)\n",
        "                else:\n",
        "                    gradients['ctr'] = torch.tensor(1e-4, device=device, dtype=torch.float32, requires_grad=True)\n",
        "            else:\n",
        "                gradients['ctr'] = torch.tensor(1e-4, device=device, dtype=torch.float32, requires_grad=True)\n",
        "        except:\n",
        "            gradients['ctr'] = torch.tensor(1e-4, device=device, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "        # Ordinal gradient\n",
        "        try:\n",
        "            if L_ord.item() > 1e-6:\n",
        "                scaled_ord_loss = lambda_ord * L_ord\n",
        "                ord_grads = torch.autograd.grad(\n",
        "                    outputs=scaled_ord_loss,\n",
        "                    inputs=trainable_params,\n",
        "                    retain_graph=True,\n",
        "                    create_graph=True,\n",
        "                    allow_unused=True\n",
        "                )\n",
        "\n",
        "                grad_squares = [torch.sum(g**2) for g in ord_grads if g is not None]\n",
        "                if grad_squares:\n",
        "                    gradients['ord'] = torch.sqrt(torch.stack(grad_squares).sum() + 1e-8)\n",
        "                else:\n",
        "                    gradients['ord'] = torch.tensor(1e-5, device=device, dtype=torch.float32, requires_grad=True)\n",
        "            else:\n",
        "                gradients['ord'] = torch.tensor(1e-5, device=device, dtype=torch.float32, requires_grad=True)\n",
        "        except:\n",
        "            gradients['ord'] = torch.tensor(1e-5, device=device, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "        return gradients, L_gen, L_ctr, L_ord\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None,\n",
        "                contrastive_anchors=None, contrastive_positives=None, contrastive_negatives=None,\n",
        "                anchor_actions=None, train_meta_params=False):\n",
        "\n",
        "        # Get current meta-parameters (detached to avoid gradient conflicts)\n",
        "        with torch.no_grad():\n",
        "            meta_params = self.meta_params.get_meta_params()\n",
        "            # Detach to prevent gradient conflicts\n",
        "            lambda_base = meta_params['lambda_base'].detach()\n",
        "            lambda_ord = meta_params['lambda_ord'].detach()\n",
        "            T_gen = meta_params['T_gen'].detach()\n",
        "            T_ctr = meta_params['T_ctr'].detach()\n",
        "\n",
        "        # Generation loss per sample\n",
        "        generation_outputs = self.base_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        if labels is not None:\n",
        "            logits = generation_outputs.logits\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "\n",
        "            loss_fct = nn.CrossEntropyLoss(reduction='none')\n",
        "            token_losses = loss_fct(\n",
        "                shift_logits.view(-1, shift_logits.size(-1)),\n",
        "                shift_labels.view(-1)\n",
        "            )\n",
        "            token_losses = token_losses.view(shift_labels.size())\n",
        "            mask = (shift_labels != -100).float()\n",
        "            generation_loss_per_sample = (token_losses * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-8)\n",
        "        else:\n",
        "            generation_loss_per_sample = torch.zeros(input_ids.size(0), device=input_ids.device)\n",
        "\n",
        "        # Initialize contrastive losses\n",
        "        contrastive_loss_per_sample = torch.zeros_like(generation_loss_per_sample)\n",
        "        ordinal_loss_per_sample = torch.zeros_like(generation_loss_per_sample)\n",
        "\n",
        "        # Contrastive losses if data available\n",
        "        if contrastive_anchors is not None and contrastive_positives is not None and contrastive_negatives is not None:\n",
        "            # Get embeddings\n",
        "            anchor_emb = self.get_text_embedding(\n",
        "                contrastive_anchors['input_ids'],\n",
        "                contrastive_anchors['attention_mask']\n",
        "            )\n",
        "            positive_emb = self.get_text_embedding(\n",
        "                contrastive_positives['input_ids'],\n",
        "                contrastive_positives['attention_mask']\n",
        "            )\n",
        "            negative_emb = self.get_text_embedding(\n",
        "                contrastive_negatives['input_ids'],\n",
        "                contrastive_negatives['attention_mask']\n",
        "            )\n",
        "\n",
        "            # Project to contrastive space\n",
        "            anchor_proj = self.contrastive_head(anchor_emb)\n",
        "            positive_proj = self.contrastive_head(positive_emb)\n",
        "            negative_proj = self.contrastive_head(negative_emb)\n",
        "\n",
        "            # Compute contrastive losses per sample\n",
        "            contrastive_loss_per_sample = self.contrastive_loss_fn(\n",
        "                anchor_proj, positive_proj, negative_proj, reduction='none'\n",
        "            )\n",
        "\n",
        "            # Ordinal loss with asymmetric margins\n",
        "            ordinal_loss_per_sample = self.ordinal_contrastive_loss_fn(\n",
        "                anchor_proj, positive_proj, negative_proj,\n",
        "                anchor_actions=anchor_actions,\n",
        "                reduction='none'\n",
        "            )\n",
        "\n",
        "        # Compute gating weights per sample (completely detached)\n",
        "        with torch.no_grad():\n",
        "            gen_loss_detached = generation_loss_per_sample.detach()\n",
        "            ctr_loss_detached = contrastive_loss_per_sample.detach()\n",
        "            ord_loss_detached = ordinal_loss_per_sample.detach()\n",
        "\n",
        "            # Gating logits per sample\n",
        "            a_gen = gen_loss_detached / T_gen\n",
        "            a_ctr = -gen_loss_detached / T_gen + ctr_loss_detached / T_ctr\n",
        "            a_ord = -gen_loss_detached / T_gen + ord_loss_detached / T_ctr\n",
        "\n",
        "            # Softmax weights per sample\n",
        "            logits_stack = torch.stack([a_gen, a_ctr, a_ord], dim=-1)\n",
        "            w = torch.softmax(logits_stack, dim=-1)\n",
        "\n",
        "            # Stability: clamp and renormalize\n",
        "            w_min = 0.05\n",
        "            w = w.clamp_min(w_min)\n",
        "            w = w / w.sum(dim=-1, keepdim=True)\n",
        "\n",
        "            w_gen = w[:, 0]\n",
        "            w_ctr = w[:, 1]\n",
        "            w_ord = w[:, 2]\n",
        "\n",
        "        # Combined loss per sample - using detached lambda values\n",
        "        scaled_ctr_loss = lambda_base * contrastive_loss_per_sample\n",
        "        scaled_ord_loss = lambda_ord * ordinal_loss_per_sample\n",
        "\n",
        "        total_loss_per_sample = (\n",
        "            w_gen * generation_loss_per_sample +\n",
        "            w_ctr * scaled_ctr_loss +\n",
        "            w_ord * scaled_ord_loss\n",
        "        )\n",
        "\n",
        "        # Main loss for model parameters\n",
        "        main_loss = total_loss_per_sample.mean()\n",
        "\n",
        "        # Store losses for meta-parameter optimization (separate from main forward pass)\n",
        "        if train_meta_params and self.step_count > 10:\n",
        "            # Store component losses for later meta-parameter update\n",
        "            self._stored_losses = {\n",
        "                'generation_loss_per_sample': generation_loss_per_sample.detach(),\n",
        "                'contrastive_loss_per_sample': contrastive_loss_per_sample.detach(),\n",
        "                'ordinal_loss_per_sample': ordinal_loss_per_sample.detach(),\n",
        "                'w_gen': w_gen,\n",
        "                'w_ctr': w_ctr,\n",
        "                'w_ord': w_ord\n",
        "            }\n",
        "\n",
        "        self.step_count += 1\n",
        "        generation_outputs.loss = main_loss\n",
        "        return generation_outputs\n",
        "\n",
        "    def update_meta_parameters(self):\n",
        "        \"\"\"Separate method to update meta-parameters after main backward pass\"\"\"\n",
        "        if not hasattr(self, '_stored_losses'):\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            stored = self._stored_losses\n",
        "\n",
        "            # Only proceed if we have meaningful contrastive data\n",
        "            if (stored['contrastive_loss_per_sample'].sum().item() > 1e-6 and\n",
        "                stored['ordinal_loss_per_sample'].sum().item() > 1e-6):\n",
        "\n",
        "                # Get fresh meta-parameters for gradient computation\n",
        "                meta_params = self.meta_params.get_meta_params()\n",
        "\n",
        "                # Compute component gradients on fresh forward pass\n",
        "                gradients, L_gen, L_ctr, L_ord = self.compute_component_gradients(\n",
        "                    stored['generation_loss_per_sample'],\n",
        "                    stored['contrastive_loss_per_sample'],\n",
        "                    stored['ordinal_loss_per_sample'],\n",
        "                    meta_params\n",
        "                )\n",
        "\n",
        "                # Update loss history\n",
        "                self.meta_params.update_loss_history(L_gen, L_ctr, L_ord)\n",
        "\n",
        "                # Compute loss ratios\n",
        "                ratios = self.meta_params.compute_loss_ratios(gamma=0.5)\n",
        "\n",
        "                # Convert ratios to tensors\n",
        "                device = L_gen.device\n",
        "                ratio_gen = torch.tensor(ratios['gen'], device=device, dtype=torch.float32)\n",
        "                ratio_ctr = torch.tensor(ratios['ctr'], device=device, dtype=torch.float32)\n",
        "                ratio_ord = torch.tensor(ratios['ord'], device=device, dtype=torch.float32)\n",
        "\n",
        "                # Target gradient norms\n",
        "                G_avg = (gradients['gen'] + gradients['ctr'] + gradients['ord']) / 3.0\n",
        "\n",
        "                targets = {\n",
        "                    'gen': G_avg * ratio_gen,\n",
        "                    'ctr': G_avg * ratio_ctr,\n",
        "                    'ord': G_avg * ratio_ord\n",
        "                }\n",
        "\n",
        "                # GradNorm loss\n",
        "                gradnorm_components = []\n",
        "                for k in ['gen', 'ctr', 'ord']:\n",
        "                    if gradients[k].requires_grad and targets[k].requires_grad:\n",
        "                        grad_diff = torch.abs(gradients[k] - targets[k])\n",
        "                        gradnorm_components.append(grad_diff)\n",
        "\n",
        "                if gradnorm_components:\n",
        "                    gradnorm_loss = torch.stack(gradnorm_components).sum()\n",
        "\n",
        "                    # Entropy regularizer\n",
        "                    w_batch = torch.stack([stored['w_gen'], stored['w_ctr'], stored['w_ord']], dim=1)\n",
        "                    log_weights = torch.log(w_batch + 1e-8)\n",
        "                    entropy_per_sample = -(w_batch * log_weights).sum(dim=1)\n",
        "                    avg_entropy = entropy_per_sample.mean()\n",
        "                    entropy_reg = 0.01 * avg_entropy\n",
        "\n",
        "                    # Total meta-objective\n",
        "                    meta_loss = gradnorm_loss + entropy_reg\n",
        "\n",
        "                    # Initialize meta-optimizer\n",
        "                    if self.meta_optimizer is None:\n",
        "                        self.meta_optimizer = torch.optim.Adam(self.meta_params.parameters(), lr=1e-4)\n",
        "\n",
        "                    # Update meta-parameters\n",
        "                    self.meta_optimizer.zero_grad()\n",
        "                    meta_loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.meta_params.parameters(), max_norm=1.0)\n",
        "                    self.meta_optimizer.step()\n",
        "\n",
        "                    if self.step_count % 20 == 0:\n",
        "                        print(f\"GradNorm - Step {self.step_count}: meta_loss={meta_loss.item():.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Meta-parameter update failed: {e}\")\n",
        "\n",
        "        finally:\n",
        "            # Clean up stored losses\n",
        "            if hasattr(self, '_stored_losses'):\n",
        "                delattr(self, '_stored_losses')\n",
        "\n",
        "# Wrap model with GradNorm capabilities\n",
        "model = GradNormContrastiveLoRAModel(model)\n",
        "print(\"GradNorm Contrastive LoRA model configured\")\n",
        "\n",
        "# STEP 7: Data Processor\n",
        "print(\"\\nSTEP 7: Enhanced Few-Shot + Ordinal Contrastive processor...\")\n",
        "\n",
        "class A3CGOrdinalFewShotDataProcessor:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.system_prompt = \"\"\"You are an expert in ESG analysis. Extract aspect-action pairs from sustainability statements.\n",
        "\n",
        "CRITICAL INSTRUCTIONS:\n",
        "- Extract EXACT terms from the input text\n",
        "- Do not paraphrase or interpret creatively\n",
        "- Use literal wording from the sentence\n",
        "- Focus on specific terms rather than general concepts\n",
        "\n",
        "DEFINITIONS:\n",
        "- Aspect: A sustainability-related entity, goal, sub-area, or activity (use exact wording)\n",
        "- Action: \"implemented\", \"planning\", or \"indeterminate\"\n",
        "\n",
        "OUTPUT FORMAT: (\"aspect1\", \"action1\"), (\"aspect2\", \"action2\"), ...\n",
        "If none: (\"no aspect\", \"no action\")\"\"\"\n",
        "\n",
        "        self.few_shot_examples = [\n",
        "            {\n",
        "                \"text\": \"We have implemented solar panels to reduce energy consumption in our facilities.\",\n",
        "                \"output\": '(\"solar panels\", \"implemented\"), (\"energy consumption\", \"implemented\")'\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"The company plans to improve workplace diversity initiatives next year.\",\n",
        "                \"output\": '(\"workplace diversity initiatives\", \"planning\")'\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"We are committed to enhancing our environmental management systems.\",\n",
        "                \"output\": '(\"environmental management systems\", \"planning\")'\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"Our recycling program has achieved a 50% waste reduction.\",\n",
        "                \"output\": '(\"recycling program\", \"implemented\"), (\"waste reduction\", \"implemented\")'\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"The board may consider sustainability investments where feasible.\",\n",
        "                \"output\": '(\"sustainability investments\", \"indeterminate\")'\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        self.contrastive_generator = ContrastiveDataGenerator()\n",
        "\n",
        "    def get_few_shot_examples(self, n_examples: int = 3) -> str:\n",
        "        \"\"\"Randomly selects n examples for few-shot\"\"\"\n",
        "        selected = random.sample(self.few_shot_examples, min(n_examples, len(self.few_shot_examples)))\n",
        "        examples_text = \"\"\n",
        "        for i, example in enumerate(selected, 1):\n",
        "            examples_text += f\"\\nExample {i}:\\n\"\n",
        "            examples_text += f\"Text: {example['text']}\\n\"\n",
        "            examples_text += f\"Output: {example['output']}\\n\"\n",
        "        return examples_text\n",
        "\n",
        "    def create_prompt(self, text: str, aspects_dict: Dict = None) -> str:\n",
        "        \"\"\"Creates a prompt using the Llama 3 chat format\"\"\"\n",
        "        few_shot_text = self.get_few_shot_examples(n_examples=3)\n",
        "        user_content = (\n",
        "            f\"{few_shot_text.strip()}\\n\\n\"\n",
        "            f\"Now extract from this text:\\n\"\n",
        "            f\"Text: {text}\\n\\n\"\n",
        "            f\"Extract the aspect-action pairs:\"\n",
        "        )\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_content}\n",
        "        ]\n",
        "\n",
        "        if aspects_dict:\n",
        "            output_pairs = []\n",
        "            for aspect, actions in aspects_dict.items():\n",
        "                for action in actions:\n",
        "                    output_pairs.append(f'(\"{aspect}\", \"{action}\")')\n",
        "            expected_output = ', '.join(output_pairs) if output_pairs else '(\"no aspect\", \"no action\")'\n",
        "            messages.append({\"role\": \"assistant\", \"content\": expected_output})\n",
        "\n",
        "        return self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True if aspects_dict is None else False\n",
        "        )\n",
        "\n",
        "    def load_data(self, file_path: str) -> List[Dict]:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def prepare_dataset(self, data: List[Dict]) -> Tuple[Dataset, List[ContrastiveSample]]:\n",
        "        \"\"\"Prepare dataset with generation and ordinal contrastive samples\"\"\"\n",
        "        print(f\"  Preparing {len(data)} samples...\")\n",
        "\n",
        "        prompts = []\n",
        "        for i, item in enumerate(data):\n",
        "            if i % 100 == 0:\n",
        "                print(f\"    Progress: {i}/{len(data)}\")\n",
        "            prompt = self.create_prompt(item['text'], item.get('aspects', {}))\n",
        "            prompts.append(prompt)\n",
        "\n",
        "        print(\"  Generating ordinal contrastive samples...\")\n",
        "        contrastive_samples = self.contrastive_generator.create_ordinal_directional_pairs(data, n_pairs=len(data)//2)\n",
        "\n",
        "        return Dataset.from_dict({\"text\": prompts}), contrastive_samples\n",
        "\n",
        "print(\"Enhanced processor configured\")\n",
        "\n",
        "# STEP 8: Data Preparation\n",
        "print(\"\\nSTEP 8: Data preparation...\")\n",
        "\n",
        "processor = A3CGOrdinalFewShotDataProcessor(tokenizer=tokenizer)\n",
        "\n",
        "train_data = processor.load_data(f\"{dataset_base}/seen_train.json\")\n",
        "val_data = processor.load_data(f\"{dataset_base}/seen_val.json\")\n",
        "\n",
        "print(f\"Train: {len(train_data)} samples\")\n",
        "print(f\"Validation: {len(val_data)} samples\")\n",
        "\n",
        "train_dataset, train_contrastive = processor.prepare_dataset(train_data)\n",
        "val_dataset, val_contrastive = processor.prepare_dataset(val_data)\n",
        "\n",
        "# Tokenization\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=2048,\n",
        "        return_tensors=None\n",
        "    )\n",
        "\n",
        "print(\"Tokenizing data...\")\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=val_dataset.column_names)\n",
        "\n",
        "print(\"Data preparation completed\")\n",
        "\n",
        "# STEP 9: Data Collator\n",
        "print(\"\\nSTEP 9: Enhanced data collator...\")\n",
        "\n",
        "class ContrastiveDataCollator:\n",
        "    \"\"\"Enhanced data collator with ordinal directional support\"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer, contrastive_samples: list, contrastive_prob: float = 0.3,\n",
        "                 contrastive_max_length: int = 512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.contrastive_samples = contrastive_samples\n",
        "        self.contrastive_prob = contrastive_prob\n",
        "        self.contrastive_max_length = contrastive_max_length\n",
        "\n",
        "    def __call__(self, features: list) -> dict:\n",
        "        batch = self.tokenizer.pad(features, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "        if \"labels\" not in features[0]:\n",
        "            batch[\"labels\"] = batch[\"input_ids\"].clone()\n",
        "\n",
        "        # Inject contrastive samples\n",
        "        if random.random() < self.contrastive_prob and self.contrastive_samples:\n",
        "            batch_size = batch['input_ids'].shape[0]\n",
        "            selected_contrastive = random.sample(\n",
        "                self.contrastive_samples,\n",
        "                min(batch_size, len(self.contrastive_samples))\n",
        "            )\n",
        "\n",
        "            anchor_texts = [cs.anchor_text for cs in selected_contrastive]\n",
        "            positive_texts = [cs.positive_text for cs in selected_contrastive]\n",
        "            negative_texts = [cs.negative_text for cs in selected_contrastive]\n",
        "            anchor_actions = [cs.anchor_action_type for cs in selected_contrastive]\n",
        "\n",
        "            anchor_tokens = self.tokenizer(\n",
        "                anchor_texts, truncation=True, padding=True,\n",
        "                max_length=self.contrastive_max_length, return_tensors=\"pt\"\n",
        "            )\n",
        "            positive_tokens = self.tokenizer(\n",
        "                positive_texts, truncation=True, padding=True,\n",
        "                max_length=self.contrastive_max_length, return_tensors=\"pt\"\n",
        "            )\n",
        "            negative_tokens = self.tokenizer(\n",
        "                negative_texts, truncation=True, padding=True,\n",
        "                max_length=self.contrastive_max_length, return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            batch['contrastive_anchors'] = anchor_tokens\n",
        "            batch['contrastive_positives'] = positive_tokens\n",
        "            batch['contrastive_negatives'] = negative_tokens\n",
        "            batch['anchor_actions'] = anchor_actions\n",
        "\n",
        "        return batch\n",
        "\n",
        "data_collator = ContrastiveDataCollator(\n",
        "    tokenizer=tokenizer,\n",
        "    contrastive_samples=train_contrastive,\n",
        "    contrastive_prob=0.3,\n",
        "    contrastive_max_length=512\n",
        ")\n",
        "\n",
        "print(\"Data collator configured\")\n",
        "\n",
        "# STEP 10: Training Callback\n",
        "print(\"\\nSTEP 10: Training callback...\")\n",
        "\n",
        "class GradNormMonitorCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.start_time = time.time()\n",
        "        self.last_check = time.time()\n",
        "\n",
        "    def on_step_end(self, args, state, control, model=None, **kwargs):\n",
        "        current_time = time.time()\n",
        "        step = state.global_step\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            elapsed = current_time - self.start_time\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                allocated = torch.cuda.memory_allocated() / 1e9\n",
        "                reserved = torch.cuda.memory_reserved() / 1e9\n",
        "                print(f\"Step {step}: GPU {allocated:.1f}/{reserved:.1f} GB, Time: {elapsed/60:.1f}min\")\n",
        "\n",
        "                if reserved / torch.cuda.get_device_properties(0).total_memory * 1e9 > 0.9:\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            if hasattr(model, 'meta_params') and step % 50 == 0:\n",
        "                meta_params = model.meta_params.get_meta_params()\n",
        "                print(f\"  Meta-params - lambda_base: {meta_params['lambda_base']:.4f}, \"\n",
        "                      f\"lambda_ord: {meta_params['lambda_ord']:.4f}\")\n",
        "\n",
        "            self.last_check = current_time\n",
        "\n",
        "    def on_epoch_end(self, args, state, control, model=None, **kwargs):\n",
        "        epoch = state.epoch\n",
        "        elapsed = time.time() - self.start_time\n",
        "        print(f\"Epoch {epoch} completed in {elapsed/60:.1f} minutes\")\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "memory_callback = GradNormMonitorCallback()\n",
        "\n",
        "# STEP 11: Custom Trainer\n",
        "print(\"\\nSTEP 11: Custom Trainer...\")\n",
        "\n",
        "class GradNormTrainer(Trainer):\n",
        "    \"\"\"Custom trainer with GradNorm meta-parameter updates\"\"\"\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        \"\"\"Custom loss computation with meta-parameter training\"\"\"\n",
        "\n",
        "        train_meta_params = self.state.global_step > 20\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            labels=inputs.get('labels'),\n",
        "            contrastive_anchors=inputs.get('contrastive_anchors'),\n",
        "            contrastive_positives=inputs.get('contrastive_positives'),\n",
        "            contrastive_negatives=inputs.get('contrastive_negatives'),\n",
        "            anchor_actions=inputs.get('anchor_actions'),\n",
        "            train_meta_params=train_meta_params\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
        "        \"\"\"Override training step to include meta-parameter updates\"\"\"\n",
        "\n",
        "        # Standard training step\n",
        "        loss = super().training_step(model, inputs, num_items_in_batch)\n",
        "\n",
        "        # Update meta-parameters after main backward pass (if enabled)\n",
        "        if self.state.global_step > 20:\n",
        "            try:\n",
        "                model.update_meta_parameters()\n",
        "            except Exception as e:\n",
        "                print(f\"Meta-parameter update failed in training step: {e}\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "# STEP 12: Training Configuration\n",
        "print(\"\\nSTEP 12: Training configuration...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/A3CG_GradNorm_Ordinal_Models\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=16,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=100,\n",
        "    logging_steps=10,\n",
        "    learning_rate=3e-5,\n",
        "    weight_decay=0.01,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    max_grad_norm=1.0,\n",
        "    warmup_ratio=0.1,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    eval_steps=100,\n",
        "    eval_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = GradNormTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.add_callback(memory_callback)\n",
        "\n",
        "print(\"Trainer configured\")\n",
        "\n",
        "# STEP 13: Training Execution\n",
        "print(\"\\nSTEP 13: STARTING GRADNORM ORDINAL DIRECTIONAL TRAINING...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"Start time: {time.strftime('%H:%M:%S')}\")\n",
        "print(f\"Base Model: {model_name}\")\n",
        "print(f\"Configuration: LoRA + Ordinal Directional Contrastive + Few-Shot + GradNorm\")\n",
        "print(f\"Batch: {training_args.per_device_train_batch_size}x{training_args.gradient_accumulation_steps}\")\n",
        "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"Ordinal Rules:\")\n",
        "print(f\"  - implemented -> planning (pos) vs indeterminate (neg)\")\n",
        "print(f\"  - indeterminate -> planning (pos) vs implemented (neg)\")\n",
        "print(f\"  - planning -> implemented (pos) vs indeterminate (neg)\")\n",
        "print(f\"Margins: Planning=0.15, Base=0.1\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    trainer.train()\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\nGRADNORM ORDINAL DIRECTIONAL TRAINING COMPLETED!\")\n",
        "    print(f\"Total time: {training_time/3600:.1f}h ({training_time/60:.1f}min)\")\n",
        "\n",
        "    # Print final meta-parameters\n",
        "    final_meta_params = model.meta_params.get_meta_params()\n",
        "    print(f\"\\nFinal Meta-Parameters:\")\n",
        "    for k, v in final_meta_params.items():\n",
        "        print(f\"  {k}: {v.item():.6f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nERROR DURING TRAINING: {e}\")\n",
        "    torch.cuda.empty_cache()\n",
        "    raise e\n",
        "\n",
        "# STEP 14: Model Saving\n",
        "model_output_path = f\"./Llama3-8B-gradnorm-ordinal-lora-final\"\n",
        "print(f\"\\nSTEP 14: Saving model to {model_output_path}...\")\n",
        "\n",
        "try:\n",
        "    trainer.model.base_model.save_pretrained(model_output_path)\n",
        "    tokenizer.save_pretrained(model_output_path)\n",
        "\n",
        "    # Save additional components\n",
        "    torch.save(trainer.model.contrastive_head.state_dict(), f\"{model_output_path}/contrastive_head.pt\")\n",
        "    torch.save(trainer.model.meta_params.state_dict(), f\"{model_output_path}/meta_parameters.pt\")\n",
        "\n",
        "    # Save configurations\n",
        "    final_meta_params = trainer.model.meta_params.get_meta_params()\n",
        "    config = {\n",
        "        'final_meta_params': {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in final_meta_params.items()},\n",
        "        'ordinal_config': {\n",
        "            'base_margin': trainer.model.ordinal_contrastive_loss_fn.base_margin,\n",
        "            'planning_margin': trainer.model.ordinal_contrastive_loss_fn.planning_margin,\n",
        "            'ordinal_rules': {\n",
        "                'implemented': {'positive': 'planning', 'negative': 'indeterminate'},\n",
        "                'indeterminate': {'positive': 'planning', 'negative': 'implemented'},\n",
        "                'planning': {'positive': 'implemented', 'negative': 'indeterminate'}\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(f\"{model_output_path}/config.json\", 'w') as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "\n",
        "    print(f\"Model saved successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Save error: {e}\")\n",
        "\n",
        "# STEP 15: Backup to Drive\n",
        "print(\"\\nSTEP 15: Backup to Google Drive...\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "\n",
        "try:\n",
        "    drive_folder = f\"/content/drive/MyDrive/A3CG_GradNorm_Ordinal_Models\"\n",
        "    os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "    drive_model_path = f\"{drive_folder}/gradnorm-ordinal-{timestamp}\"\n",
        "    shutil.copytree(model_output_path, drive_model_path)\n",
        "\n",
        "    total_size_mb = sum(os.path.getsize(os.path.join(drive_model_path, f))\n",
        "                       for f in os.listdir(drive_model_path)) / (1024*1024)\n",
        "\n",
        "    print(f\"Model backed up to: {drive_model_path}\")\n",
        "    print(f\"Total size: {total_size_mb:.1f} MB\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Backup error: {e}\")\n",
        "\n",
        "# STEP 16: Final Summary\n",
        "print(\"\\nSTEP 16: Training completed successfully!\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"End time: {time.strftime('%H:%M:%S')}\")\n",
        "print(f\"Model location: {model_output_path}\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "Tm7tB3-GamgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# GRADNORM + ORDINAL CONTRASTIVE MODEL EVALUATION SCRIPT\n",
        "# Compatible with GradNorm Meta-Parameters + Ordinal Directional Learning\n",
        "# =====================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "from difflib import SequenceMatcher\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import PeftModel, PeftConfig\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"GRADNORM + ORDINAL CONTRASTIVE MODEL EVALUATION SCRIPT\")\n",
        "print(\"Compatible with GradNorm Meta-Parameters + Ordinal Directional Learning\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Start time: {time.strftime('%H:%M:%S')}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Step 1: Exact GradNorm Model Classes\n",
        "print(\"Step 1: Import GradNorm + Ordinal Contrastive classes...\")\n",
        "\n",
        "# Meta-Parameters Manager (exactly as in training)\n",
        "class MetaParametersManager(nn.Module):\n",
        "    def __init__(self, initial_lambda_base=0.15, initial_lambda_ord=0.04,\n",
        "                 initial_T_gen=2.5, initial_T_ctr=0.8, epsilon=1e-6):\n",
        "        super().__init__()\n",
        "\n",
        "        def safe_inverse_softplus(x):\n",
        "            return float(np.log(np.exp(float(x)) - 1.0))\n",
        "\n",
        "        self.rho_base = nn.Parameter(\n",
        "            torch.tensor(safe_inverse_softplus(initial_lambda_base - epsilon),\n",
        "                        dtype=torch.float32),\n",
        "            requires_grad=True\n",
        "        )\n",
        "        self.rho_ord = nn.Parameter(\n",
        "            torch.tensor(safe_inverse_softplus(initial_lambda_ord - epsilon),\n",
        "                        dtype=torch.float32),\n",
        "            requires_grad=True\n",
        "        )\n",
        "        self.tau_gen = nn.Parameter(\n",
        "            torch.tensor(safe_inverse_softplus(initial_T_gen - epsilon),\n",
        "                        dtype=torch.float32),\n",
        "            requires_grad=True\n",
        "        )\n",
        "        self.tau_ctr = nn.Parameter(\n",
        "            torch.tensor(safe_inverse_softplus(initial_T_ctr - epsilon),\n",
        "                        dtype=torch.float32),\n",
        "            requires_grad=True\n",
        "        )\n",
        "\n",
        "        self.epsilon = epsilon\n",
        "        self.loss_history = {'gen': [], 'ctr': [], 'ord': []}\n",
        "        self.initial_losses = {'gen': None, 'ctr': None, 'ord': None}\n",
        "\n",
        "    def get_meta_params(self):\n",
        "        lambda_base = F.softplus(self.rho_base) + self.epsilon\n",
        "        lambda_ord = F.softplus(self.rho_ord) + self.epsilon\n",
        "        T_gen = F.softplus(self.tau_gen) + self.epsilon\n",
        "        T_ctr = F.softplus(self.tau_ctr) + self.epsilon\n",
        "\n",
        "        return {\n",
        "            'lambda_base': lambda_base,\n",
        "            'lambda_ord': lambda_ord,\n",
        "            'T_gen': T_gen,\n",
        "            'T_ctr': T_ctr\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class ContrastiveSample:\n",
        "    anchor_text: str\n",
        "    anchor_aspects: Dict\n",
        "    positive_text: str\n",
        "    positive_aspects: Dict\n",
        "    negative_text: str\n",
        "    negative_aspects: Dict\n",
        "    anchor_action_type: str = None\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, anchor_emb, positive_emb, negative_emb, reduction='mean'):\n",
        "        anchor_emb = F.normalize(anchor_emb, p=2, dim=1)\n",
        "        positive_emb = F.normalize(positive_emb, p=2, dim=1)\n",
        "        negative_emb = F.normalize(negative_emb, p=2, dim=1)\n",
        "\n",
        "        pos_sim = F.cosine_similarity(anchor_emb, positive_emb, dim=1)\n",
        "        neg_sim = F.cosine_similarity(anchor_emb, negative_emb, dim=1)\n",
        "\n",
        "        pos_exp = torch.exp(pos_sim / self.temperature)\n",
        "        neg_exp = torch.exp(neg_sim / self.temperature)\n",
        "\n",
        "        loss_per_sample = -torch.log(pos_exp / (pos_exp + neg_exp + 1e-8))\n",
        "\n",
        "        if reduction == 'mean':\n",
        "            return loss_per_sample.mean()\n",
        "        elif reduction == 'none':\n",
        "            return loss_per_sample\n",
        "        else:\n",
        "            raise ValueError(f\"reduction must be 'mean' or 'none', got {reduction}\")\n",
        "\n",
        "class OrdinalContrastiveLoss(nn.Module):\n",
        "    def __init__(self, base_margin: float = 0.10, planning_margin: float = 0.15):\n",
        "        super().__init__()\n",
        "        self.base_margin = base_margin\n",
        "        self.planning_margin = planning_margin\n",
        "\n",
        "        self.action_margins = {\n",
        "            'implemented': base_margin,\n",
        "            'indeterminate': base_margin,\n",
        "            'planning': planning_margin\n",
        "        }\n",
        "\n",
        "    def forward(self, anchor_emb, positive_emb, negative_emb, anchor_actions=None, reduction='mean'):\n",
        "        anchor_emb = F.normalize(anchor_emb, p=2, dim=1)\n",
        "        positive_emb = F.normalize(positive_emb, p=2, dim=1)\n",
        "        negative_emb = F.normalize(negative_emb, p=2, dim=1)\n",
        "\n",
        "        distance_0_1 = 1 - F.cosine_similarity(anchor_emb, positive_emb, dim=1)\n",
        "        distance_0_2 = 1 - F.cosine_similarity(anchor_emb, negative_emb, dim=1)\n",
        "\n",
        "        if anchor_actions is not None:\n",
        "            margins = torch.tensor([\n",
        "                self.action_margins.get(action, self.base_margin)\n",
        "                for action in anchor_actions\n",
        "            ], device=anchor_emb.device, dtype=anchor_emb.dtype)\n",
        "        else:\n",
        "            margins = torch.full((anchor_emb.size(0),), self.base_margin,\n",
        "                               device=anchor_emb.device, dtype=anchor_emb.dtype)\n",
        "\n",
        "        loss_per_sample = F.relu(distance_0_1 - distance_0_2 + margins)\n",
        "\n",
        "        if reduction == 'mean':\n",
        "            return loss_per_sample.mean()\n",
        "        elif reduction == 'none':\n",
        "            return loss_per_sample\n",
        "        else:\n",
        "            raise ValueError(f\"reduction must be 'mean' or 'none', got {reduction}\")\n",
        "\n",
        "class GradNormContrastiveLoRAModel(nn.Module):\n",
        "    \"\"\"GradNorm model with meta-parameter optimization\"\"\"\n",
        "\n",
        "    def __init__(self, base_model, hidden_size=4096, contrastive_dim=256):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.contrastive_dim = contrastive_dim\n",
        "\n",
        "        # Contrastive projection head\n",
        "        self.contrastive_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(hidden_size // 2, contrastive_dim)\n",
        "        )\n",
        "\n",
        "        # Loss functions with asymmetric margins\n",
        "        self.contrastive_loss_fn = ContrastiveLoss(temperature=0.1)\n",
        "        self.ordinal_contrastive_loss_fn = OrdinalContrastiveLoss(\n",
        "            base_margin=0.10,\n",
        "            planning_margin=0.15\n",
        "        )\n",
        "\n",
        "        # Meta-parameters manager\n",
        "        self.meta_params = MetaParametersManager()\n",
        "\n",
        "        self.step_count = 0\n",
        "        self.meta_optimizer = None\n",
        "\n",
        "    def get_text_embedding(self, input_ids, attention_mask):\n",
        "        with torch.no_grad():\n",
        "            outputs = self.base_model.base_model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                output_hidden_states=True\n",
        "            )\n",
        "\n",
        "            last_hidden = outputs.hidden_states[-1]\n",
        "            mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size())\n",
        "            sum_hidden = torch.sum(last_hidden * mask_expanded, dim=1)\n",
        "            sum_mask = torch.sum(mask_expanded, dim=1)\n",
        "            mean_hidden = sum_hidden / sum_mask\n",
        "\n",
        "            return mean_hidden\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None,\n",
        "                contrastive_anchors=None, contrastive_positives=None, contrastive_negatives=None,\n",
        "                anchor_actions=None, train_meta_params=False):\n",
        "\n",
        "        # Get current meta-parameters (detached for inference)\n",
        "        with torch.no_grad():\n",
        "            meta_params = self.meta_params.get_meta_params()\n",
        "            lambda_base = meta_params['lambda_base'].detach()\n",
        "            lambda_ord = meta_params['lambda_ord'].detach()\n",
        "            T_gen = meta_params['T_gen'].detach()\n",
        "            T_ctr = meta_params['T_ctr'].detach()\n",
        "\n",
        "        # Generation loss\n",
        "        generation_outputs = self.base_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        if labels is not None:\n",
        "            logits = generation_outputs.logits\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "\n",
        "            loss_fct = nn.CrossEntropyLoss(reduction='none')\n",
        "            token_losses = loss_fct(\n",
        "                shift_logits.view(-1, shift_logits.size(-1)),\n",
        "                shift_labels.view(-1)\n",
        "            )\n",
        "            token_losses = token_losses.view(shift_labels.size())\n",
        "            mask = (shift_labels != -100).float()\n",
        "            generation_loss_per_sample = (token_losses * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-8)\n",
        "        else:\n",
        "            generation_loss_per_sample = torch.zeros(input_ids.size(0), device=input_ids.device)\n",
        "\n",
        "        contrastive_loss_per_sample = torch.zeros_like(generation_loss_per_sample)\n",
        "        ordinal_loss_per_sample = torch.zeros_like(generation_loss_per_sample)\n",
        "\n",
        "        # Contrastive losses if data available\n",
        "        if contrastive_anchors is not None and contrastive_positives is not None and contrastive_negatives is not None:\n",
        "            anchor_emb = self.get_text_embedding(\n",
        "                contrastive_anchors['input_ids'],\n",
        "                contrastive_anchors['attention_mask']\n",
        "            )\n",
        "            positive_emb = self.get_text_embedding(\n",
        "                contrastive_positives['input_ids'],\n",
        "                contrastive_positives['attention_mask']\n",
        "            )\n",
        "            negative_emb = self.get_text_embedding(\n",
        "                contrastive_negatives['input_ids'],\n",
        "                contrastive_negatives['attention_mask']\n",
        "            )\n",
        "\n",
        "            anchor_proj = self.contrastive_head(anchor_emb)\n",
        "            positive_proj = self.contrastive_head(positive_emb)\n",
        "            negative_proj = self.contrastive_head(negative_emb)\n",
        "\n",
        "            contrastive_loss_per_sample = self.contrastive_loss_fn(\n",
        "                anchor_proj, positive_proj, negative_proj, reduction='none'\n",
        "            )\n",
        "\n",
        "            ordinal_loss_per_sample = self.ordinal_contrastive_loss_fn(\n",
        "                anchor_proj, positive_proj, negative_proj,\n",
        "                anchor_actions=anchor_actions,\n",
        "                reduction='none'\n",
        "            )\n",
        "\n",
        "        # Gating weights per sample\n",
        "        with torch.no_grad():\n",
        "            gen_loss_detached = generation_loss_per_sample.detach()\n",
        "            ctr_loss_detached = contrastive_loss_per_sample.detach()\n",
        "            ord_loss_detached = ordinal_loss_per_sample.detach()\n",
        "\n",
        "            a_gen = gen_loss_detached / T_gen\n",
        "            a_ctr = -gen_loss_detached / T_gen + ctr_loss_detached / T_ctr\n",
        "            a_ord = -gen_loss_detached / T_gen + ord_loss_detached / T_ctr\n",
        "\n",
        "            logits_stack = torch.stack([a_gen, a_ctr, a_ord], dim=-1)\n",
        "            w = torch.softmax(logits_stack, dim=-1)\n",
        "\n",
        "            w_min = 0.05\n",
        "            w = w.clamp_min(w_min)\n",
        "            w = w / w.sum(dim=-1, keepdim=True)\n",
        "\n",
        "            w_gen = w[:, 0]\n",
        "            w_ctr = w[:, 1]\n",
        "            w_ord = w[:, 2]\n",
        "\n",
        "        # Combined loss\n",
        "        scaled_ctr_loss = lambda_base * contrastive_loss_per_sample\n",
        "        scaled_ord_loss = lambda_ord * ordinal_loss_per_sample\n",
        "\n",
        "        total_loss_per_sample = (\n",
        "            w_gen * generation_loss_per_sample +\n",
        "            w_ctr * scaled_ctr_loss +\n",
        "            w_ord * scaled_ord_loss\n",
        "        )\n",
        "\n",
        "        main_loss = total_loss_per_sample.mean()\n",
        "        generation_outputs.loss = main_loss\n",
        "        return generation_outputs\n",
        "\n",
        "    def generate(self, *args, **kwargs):\n",
        "        return self.base_model.generate(*args, **kwargs)\n",
        "\n",
        "print(\"GradNorm + Ordinal Contrastive classes imported\")\n",
        "\n",
        "# Step 2: GradNorm Model Loading\n",
        "print(\"\\nStep 2: Loading trained GradNorm model...\")\n",
        "\n",
        "MODEL_BASE = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Configure paths\n",
        "DATA_DIR = \"/content/A3CG_DATASET/folds/fold_1\"\n",
        "DRIVE_DATA_DIR = \"/content/drive/MyDrive/A3CG_Dataset/folds/fold_1\"\n",
        "\n",
        "if os.path.exists(DATA_DIR):\n",
        "    print(f\"Using data directory: {DATA_DIR}\")\n",
        "elif os.path.exists(DRIVE_DATA_DIR):\n",
        "    DATA_DIR = DRIVE_DATA_DIR\n",
        "    print(f\"Using Drive data directory: {DATA_DIR}\")\n",
        "else:\n",
        "    print(\"Data directory not found!\")\n",
        "\n",
        "def load_gradnorm_model_robust(model_path: str):\n",
        "    \"\"\"Robust loading of GradNorm + Ordinal model\"\"\"\n",
        "\n",
        "    print(f\"Analyzing GradNorm model: {model_path}\")\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
        "\n",
        "    files_in_model = os.listdir(model_path)\n",
        "    print(f\"Files found: {files_in_model}\")\n",
        "\n",
        "    # Load tokenizer\n",
        "    print(\"Loading tokenizer...\")\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        print(\"Tokenizer loaded from model\")\n",
        "    except:\n",
        "        print(\"Fallback: tokenizer from base model\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_BASE)\n",
        "\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Load base model\n",
        "    print(\"Loading base model...\")\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_BASE,\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        trust_remote_code=True,\n",
        "        attn_implementation=\"flash_attention_2\"\n",
        "    )\n",
        "\n",
        "    # Load LoRA adapters\n",
        "    print(\"Loading LoRA adapters...\")\n",
        "    lora_model = PeftModel.from_pretrained(\n",
        "        base_model,\n",
        "        model_path,\n",
        "        torch_dtype=torch.bfloat16\n",
        "    )\n",
        "\n",
        "    # Create GradNorm model\n",
        "    print(\"Creating GradNorm model...\")\n",
        "    hidden_size = base_model.config.hidden_size\n",
        "    print(f\"Detected hidden size: {hidden_size}\")\n",
        "\n",
        "    gradnorm_model = GradNormContrastiveLoRAModel(\n",
        "        base_model=lora_model,\n",
        "        hidden_size=hidden_size,\n",
        "        contrastive_dim=256\n",
        "    )\n",
        "\n",
        "    # Load contrastive head\n",
        "    contrastive_head_path = os.path.join(model_path, \"contrastive_head.pt\")\n",
        "\n",
        "    if os.path.exists(contrastive_head_path):\n",
        "        print(\"Loading contrastive head...\")\n",
        "        try:\n",
        "            state_dict = torch.load(contrastive_head_path, map_location='cpu')\n",
        "            print(f\"Contrastive weights loaded: {list(state_dict.keys())}\")\n",
        "\n",
        "            gradnorm_model.contrastive_head.load_state_dict(state_dict)\n",
        "            device = next(gradnorm_model.base_model.parameters()).device\n",
        "            gradnorm_model.contrastive_head.to(device)\n",
        "            print(\"Contrastive head loaded successfully\")\n",
        "            contrastive_loaded = True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading contrastive head: {e}\")\n",
        "            contrastive_loaded = False\n",
        "    else:\n",
        "        print(\"No contrastive head found\")\n",
        "        contrastive_loaded = False\n",
        "\n",
        "    # Load GradNorm meta-parameters\n",
        "    meta_params_path = os.path.join(model_path, \"meta_parameters.pt\")\n",
        "\n",
        "    if os.path.exists(meta_params_path):\n",
        "        print(\"Loading GradNorm meta-parameters...\")\n",
        "        try:\n",
        "            meta_state_dict = torch.load(meta_params_path, map_location='cpu')\n",
        "            print(f\"Meta-parameters loaded: {list(meta_state_dict.keys())}\")\n",
        "\n",
        "            gradnorm_model.meta_params.load_state_dict(meta_state_dict)\n",
        "            device = next(gradnorm_model.base_model.parameters()).device\n",
        "            gradnorm_model.meta_params.to(device)\n",
        "\n",
        "            # Display final values\n",
        "            final_params = gradnorm_model.meta_params.get_meta_params()\n",
        "            print(\"Meta-parameter values:\")\n",
        "            for k, v in final_params.items():\n",
        "                print(f\"  {k}: {v.item():.6f}\")\n",
        "\n",
        "            meta_loaded = True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading meta-parameters: {e}\")\n",
        "            meta_loaded = False\n",
        "    else:\n",
        "        print(\"No meta-parameters found\")\n",
        "        meta_loaded = False\n",
        "\n",
        "    # Load ordinal configuration\n",
        "    ordinal_config_path = os.path.join(model_path, \"ordinal_config.json\")\n",
        "    ordinal_config = None\n",
        "\n",
        "    if os.path.exists(ordinal_config_path):\n",
        "        print(\"Loading ordinal configuration...\")\n",
        "        try:\n",
        "            with open(ordinal_config_path, 'r') as f:\n",
        "                ordinal_config = json.load(f)\n",
        "            print(\"Ordinal configuration loaded\")\n",
        "            print(f\"  Margins: Planning={ordinal_config.get('planning_margin', 0.15)}, Base={ordinal_config.get('base_margin', 0.10)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading ordinal config: {e}\")\n",
        "\n",
        "    # Determine loading status\n",
        "    if contrastive_loaded and meta_loaded:\n",
        "        loading_status = \"gradnorm_complete\"\n",
        "    elif contrastive_loaded:\n",
        "        loading_status = \"contrastive_only\"\n",
        "    else:\n",
        "        loading_status = \"lora_only\"\n",
        "\n",
        "    return gradnorm_model, tokenizer, loading_status, ordinal_config\n",
        "\n",
        "# Find and load GradNorm model\n",
        "print(\"Searching for trained GradNorm model...\")\n",
        "\n",
        "# Possible paths for GradNorm model\n",
        "possible_paths = [\n",
        "    \"./Llama3-8B-gradnorm-ordinal-lora-final\",\n",
        "    \"/content/drive/MyDrive/A3CG_GradNorm_Ordinal_Models\"\n",
        "]\n",
        "\n",
        "# Add dynamic GradNorm folders\n",
        "for base_dir in [\"/content/drive/MyDrive/A3CG_GradNorm_Ordinal_Models\"]:\n",
        "    if os.path.exists(base_dir):\n",
        "        for folder in os.listdir(base_dir):\n",
        "            if \"gradnorm\" in folder.lower() or \"ordinal\" in folder.lower():\n",
        "                possible_paths.append(os.path.join(base_dir, folder))\n",
        "\n",
        "model_path = None\n",
        "for path in possible_paths:\n",
        "    if os.path.exists(path):\n",
        "        model_path = path\n",
        "        print(f\"GradNorm model found: {path}\")\n",
        "        break\n",
        "\n",
        "if not model_path:\n",
        "    print(\"No GradNorm model found!\")\n",
        "    print(\"Paths checked:\")\n",
        "    for path in possible_paths:\n",
        "        print(f\"  - {path}\")\n",
        "    raise FileNotFoundError(\"No GradNorm model found!\")\n",
        "\n",
        "# Load model\n",
        "model, tokenizer, loading_status, ordinal_config = load_gradnorm_model_robust(model_path)\n",
        "\n",
        "print(f\"Model loaded with status: {loading_status}\")\n",
        "\n",
        "# Step 3: GradNorm Architecture Verification\n",
        "print(\"\\nStep 3: GradNorm architecture verification...\")\n",
        "\n",
        "def verify_gradnorm_architecture(model, loading_status, ordinal_config):\n",
        "    \"\"\"Verify complete GradNorm architecture\"\"\"\n",
        "\n",
        "    print(\"Verifying GradNorm architecture...\")\n",
        "\n",
        "    if loading_status == \"gradnorm_complete\":\n",
        "        print(\"Complete GradNorm model with meta-parameters\")\n",
        "\n",
        "        # Verify meta-parameters\n",
        "        if hasattr(model, 'meta_params'):\n",
        "            print(\"Meta-parameters present\")\n",
        "            final_params = model.meta_params.get_meta_params()\n",
        "            print(\"Current meta-parameter values:\")\n",
        "            for k, v in final_params.items():\n",
        "                print(f\"  {k}: {v.item():.6f}\")\n",
        "\n",
        "        # Verify contrastive head\n",
        "        if hasattr(model, 'contrastive_head'):\n",
        "            print(\"Contrastive head present\")\n",
        "\n",
        "        # Verify ordinal margins\n",
        "        if hasattr(model, 'ordinal_contrastive_loss_fn'):\n",
        "            print(\"Ordinal loss with asymmetric margins present\")\n",
        "            print(f\"  Planning margin: {model.ordinal_contrastive_loss_fn.planning_margin}\")\n",
        "            print(f\"  Base margin: {model.ordinal_contrastive_loss_fn.base_margin}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    elif loading_status == \"contrastive_only\":\n",
        "        print(\"Contrastive model without meta-parameters\")\n",
        "        return True\n",
        "\n",
        "    else:\n",
        "        print(\"LoRA model only\")\n",
        "        return True\n",
        "\n",
        "architecture_ok = verify_gradnorm_architecture(model, loading_status, ordinal_config)\n",
        "\n",
        "if architecture_ok:\n",
        "    print(\"GradNorm architecture verified\")\n",
        "else:\n",
        "    print(\"Problem with GradNorm architecture\")\n",
        "\n",
        "# Step 4: Compatible Prompt Generator\n",
        "print(\"\\nStep 4: Prompt generator configuration...\")\n",
        "\n",
        "class A3CGGradNormEvaluationPromptGenerator:\n",
        "    def __init__(self, tokenizer, model_type: str = \"gradnorm_complete\"):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.system_prompt = \"\"\"You are an expert in ESG analysis. Extract aspect-action pairs from sustainability statements.\n",
        "\n",
        "CRITICAL INSTRUCTIONS:\n",
        "- Extract EXACT terms from the input text\n",
        "- Do not paraphrase or interpret creatively\n",
        "- Use literal wording from the sentence\n",
        "- Focus on specific terms rather than general concepts\n",
        "\n",
        "DEFINITIONS:\n",
        "- Aspect: A sustainability-related entity, goal, sub-area, or activity (use exact wording)\n",
        "- Action: \"implemented\", \"planning\", or \"indeterminate\"\n",
        "\n",
        "OUTPUT FORMAT: (\"aspect1\", \"action1\"), (\"aspect2\", \"action2\"), ...\n",
        "If none: (\"no aspect\", \"no action\")\"\"\"\n",
        "\n",
        "        self.few_shot_examples = [\n",
        "            {\n",
        "                \"text\": \"We have implemented solar panels to reduce energy consumption in our facilities.\",\n",
        "                \"output\": '(\"solar panels\", \"implemented\"), (\"energy consumption\", \"implemented\")'\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"The company plans to improve workplace diversity initiatives next year.\",\n",
        "                \"output\": '(\"workplace diversity initiatives\", \"planning\")'\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"We are committed to enhancing our environmental management systems.\",\n",
        "                \"output\": '(\"environmental management systems\", \"planning\")'\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"Our recycling program has achieved a 50% waste reduction.\",\n",
        "                \"output\": '(\"recycling program\", \"implemented\"), (\"waste reduction\", \"implemented\")'\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"The board may consider sustainability investments where feasible.\",\n",
        "                \"output\": '(\"sustainability investments\", \"indeterminate\")'\n",
        "            }\n",
        "        ]\n",
        "\n",
        "    def get_few_shot_examples(self, n_examples: int = 3) -> str:\n",
        "        selected = random.sample(self.few_shot_examples, min(n_examples, len(self.few_shot_examples)))\n",
        "        examples_text = \"\"\n",
        "        for i, example in enumerate(selected, 1):\n",
        "            examples_text += f\"\\nExample {i}:\\n\"\n",
        "            examples_text += f\"Text: {example['text']}\\n\"\n",
        "            examples_text += f\"Output: {example['output']}\\n\"\n",
        "        return examples_text\n",
        "\n",
        "    def create_prompt(self, sentence: str) -> str:\n",
        "        if self.model_type in [\"gradnorm_complete\", \"contrastive_only\"]:\n",
        "            few_shot_text = self.get_few_shot_examples(n_examples=3)\n",
        "            user_content = (\n",
        "                f\"{few_shot_text.strip()}\\n\\n\"\n",
        "                f\"Now extract from this text:\\nText: {sentence}\\n\\n\"\n",
        "                f\"Extract the aspect-action pairs:\"\n",
        "            )\n",
        "\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_content}\n",
        "            ]\n",
        "\n",
        "            return self.tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            messages = [\n",
        "                {\"role\": \"user\", \"content\": f\"Extract aspect-action pairs from: {sentence}\"}\n",
        "            ]\n",
        "            return self.tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "\n",
        "# Initialize generator\n",
        "prompt_generator = A3CGGradNormEvaluationPromptGenerator(tokenizer, loading_status)\n",
        "\n",
        "print(f\"Prompt generator configured for {loading_status}\")\n",
        "\n",
        "# Step 5: Evaluation Functions\n",
        "print(\"\\nStep 5: Evaluation functions configuration...\")\n",
        "\n",
        "def generate_prediction_gradnorm(model, tokenizer, sentence: str, model_type: str, max_length: int = 512) -> str:\n",
        "    \"\"\"Optimized prediction generation for GradNorm\"\"\"\n",
        "\n",
        "    prompt = prompt_generator.create_prompt(sentence)\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "        padding=True\n",
        "    )\n",
        "\n",
        "    device = next(model.parameters()).device if hasattr(model, 'parameters') else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Optimized generation parameters\n",
        "    gen_params = {\n",
        "        \"max_new_tokens\": 150,\n",
        "        \"do_sample\": True,\n",
        "        \"temperature\": 0.1,\n",
        "        \"top_p\": 0.9,\n",
        "        \"repetition_penalty\": 1.1,\n",
        "        \"pad_token_id\": tokenizer.eos_token_id,\n",
        "        \"eos_token_id\": tokenizer.eos_token_id,\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            outputs = model.generate(**inputs, **gen_params)\n",
        "        except Exception as e:\n",
        "            print(f\"WARNING: Generation error: {e}\")\n",
        "            outputs = model.generate(\n",
        "                inputs['input_ids'],\n",
        "                max_new_tokens=150,\n",
        "                do_sample=False,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "    generated_ids = outputs[0][inputs['input_ids'].shape[1]:]\n",
        "    response = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "    return response.strip()\n",
        "\n",
        "def parse_prediction_enhanced(prediction: str, model_type: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Enhanced parsing for tuple format\"\"\"\n",
        "    pairs = []\n",
        "\n",
        "    try:\n",
        "        # Tuple format: (\"aspect\", \"action\")\n",
        "        tuple_pattern = r'\\(\\s*[\"\\']([^\"\\']+)[\"\\']\\s*,\\s*[\"\\']([^\"\\']+)[\"\\']\\s*\\)'\n",
        "        matches = re.findall(tuple_pattern, prediction)\n",
        "\n",
        "        for aspect, action in matches:\n",
        "            aspect = aspect.strip()\n",
        "            action = action.strip()\n",
        "            if aspect and action and aspect != \"no aspect\" and action != \"no action\":\n",
        "                pairs.append((aspect.lower(), action.lower()))\n",
        "\n",
        "        # If no tuples found, try simple pattern\n",
        "        if not pairs:\n",
        "            simple_pattern = r'\\(\\s*([^,\\)]+)\\s*,\\s*([^,\\)]+)\\s*\\)'\n",
        "            simple_matches = re.findall(simple_pattern, prediction)\n",
        "\n",
        "            for aspect, action in simple_matches:\n",
        "                aspect = aspect.strip().strip('\"\\'')\n",
        "                action = action.strip().strip('\"\\'')\n",
        "                if aspect and action and aspect != \"no aspect\" and action != \"no action\":\n",
        "                    pairs.append((aspect.lower(), action.lower()))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"WARNING: Parsing error: {e}\")\n",
        "\n",
        "    return pairs\n",
        "\n",
        "# Metric functions (identical to original script)\n",
        "def calculate_metrics_exact_match(predictions: List[List[Tuple[str, str]]],\n",
        "                                 ground_truth: List[List[Tuple[str, str]]]) -> Dict:\n",
        "    \"\"\"Exact Match metrics as in A3CG paper\"\"\"\n",
        "\n",
        "    exact_matches = 0\n",
        "    partial_matches = 0\n",
        "    total_pred_pairs = 0\n",
        "    total_true_pairs = 0\n",
        "\n",
        "    exact_true_positives = 0\n",
        "    exact_false_positives = 0\n",
        "    exact_false_negatives = 0\n",
        "\n",
        "    for pred_pairs, true_pairs in zip(predictions, ground_truth):\n",
        "        total_pred_pairs += len(pred_pairs)\n",
        "        total_true_pairs += len(true_pairs)\n",
        "\n",
        "        pred_set = set(pred_pairs)\n",
        "        true_set = set(true_pairs)\n",
        "\n",
        "        matched_pairs = pred_set.intersection(true_set)\n",
        "\n",
        "        exact_true_positives += len(matched_pairs)\n",
        "        exact_false_positives += len(pred_set - true_set)\n",
        "        exact_false_negatives += len(true_set - pred_set)\n",
        "\n",
        "        if pred_set == true_set and len(pred_set) > 0:\n",
        "            exact_matches += 1\n",
        "\n",
        "        if len(matched_pairs) > 0:\n",
        "            partial_matches += 1\n",
        "\n",
        "    n_samples = len(predictions)\n",
        "\n",
        "    exact_match_accuracy = exact_matches / n_samples if n_samples > 0 else 0\n",
        "    partial_match_accuracy = partial_matches / n_samples if n_samples > 0 else 0\n",
        "\n",
        "    exact_precision = exact_true_positives / (exact_true_positives + exact_false_positives) if (exact_true_positives + exact_false_positives) > 0 else 0\n",
        "    exact_recall = exact_true_positives / (exact_true_positives + exact_false_negatives) if (exact_true_positives + exact_false_negatives) > 0 else 0\n",
        "    exact_f1_score = 2 * (exact_precision * exact_recall) / (exact_precision + exact_recall) if (exact_precision + exact_recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'exact_match_accuracy': exact_match_accuracy,\n",
        "        'partial_match_accuracy': partial_match_accuracy,\n",
        "        'exact_precision': exact_precision,\n",
        "        'exact_recall': exact_recall,\n",
        "        'exact_f1_score': exact_f1_score,\n",
        "        'exact_true_positives': exact_true_positives,\n",
        "        'exact_false_positives': exact_false_positives,\n",
        "        'exact_false_negatives': exact_false_negatives,\n",
        "        'total_predictions': total_pred_pairs,\n",
        "        'total_ground_truth': total_true_pairs,\n",
        "    }\n",
        "\n",
        "def load_test_data_flexible(file_path: str) -> Tuple[List[str], List[List[Tuple[str, str]]]]:\n",
        "    \"\"\"Flexible test data loading\"\"\"\n",
        "    print(f\"Loading: {os.path.basename(file_path)}\")\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    sentences = []\n",
        "    ground_truth = []\n",
        "\n",
        "    if isinstance(data, list):\n",
        "        for item in data:\n",
        "            if isinstance(item, dict):\n",
        "                if 'text' in item and 'aspects' in item:\n",
        "                    sentence = item['text']\n",
        "                    pairs = []\n",
        "\n",
        "                    aspects_dict = item['aspects']\n",
        "                    if isinstance(aspects_dict, dict):\n",
        "                        for aspect, actions in aspects_dict.items():\n",
        "                            if isinstance(actions, list):\n",
        "                                for action in actions:\n",
        "                                    pairs.append((aspect.strip(), action.strip()))\n",
        "                            elif isinstance(actions, str):\n",
        "                                pairs.append((aspect.strip(), actions.strip()))\n",
        "\n",
        "                    sentences.append(sentence)\n",
        "                    ground_truth.append(pairs)\n",
        "\n",
        "    print(f\"Loaded {len(sentences)} samples\")\n",
        "    return sentences, ground_truth\n",
        "\n",
        "print(\"Evaluation functions configured\")\n",
        "\n",
        "# Step 6: Test Data Loading\n",
        "print(\"\\nStep 6: Loading test data...\")\n",
        "\n",
        "test_files = {\n",
        "    'seen_test': f\"{DATA_DIR}/seen_test.json\",\n",
        "    'unseen_test': f\"{DATA_DIR}/unseen_test.json\"\n",
        "}\n",
        "\n",
        "test_data = {}\n",
        "for name, file_path in test_files.items():\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            sentences, ground_truth = load_test_data_flexible(file_path)\n",
        "            if len(sentences) > 0:\n",
        "                test_data[name] = (sentences, ground_truth)\n",
        "                print(f\"{name}: {len(sentences)} samples\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR loading {name}: {e}\")\n",
        "    else:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "\n",
        "if not test_data:\n",
        "    print(\"WARNING: No test files found - creating demo data\")\n",
        "    test_data['demo'] = (\n",
        "        [\"This company has implemented strong environmental policies.\"],\n",
        "        [[(\"environmental policies\", \"implemented\")]]\n",
        "    )\n",
        "\n",
        "# Step 7: GradNorm Model Evaluation\n",
        "print(\"\\nStep 7: GradNorm model evaluation...\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Model evaluated: {model_path}\")\n",
        "print(f\"Loading status: {loading_status}\")\n",
        "print(f\"Architecture verified: {'Yes' if architecture_ok else 'No'}\")\n",
        "\n",
        "# Display meta-parameters if available\n",
        "if loading_status == \"gradnorm_complete\" and hasattr(model, 'meta_params'):\n",
        "    print(\"\\nGradNorm Meta-parameters:\")\n",
        "    final_params = model.meta_params.get_meta_params()\n",
        "    for k, v in final_params.items():\n",
        "        print(f\"  {k}: {v.item():.6f}\")\n",
        "    print(f\"Ordinal margins: Planning={model.ordinal_contrastive_loss_fn.planning_margin}, Base={model.ordinal_contrastive_loss_fn.base_margin}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for dataset_name, (sentences, ground_truth) in test_data.items():\n",
        "    print(f\"\\nEvaluation on {dataset_name}...\")\n",
        "    print(f\"Base Model: {MODEL_BASE}\")\n",
        "    print(f\"Model type: {loading_status}\")\n",
        "    print(f\"Number of samples: {len(sentences)}\")\n",
        "\n",
        "    predictions = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    n_test = min(len(sentences), 150)  # Adjust as needed\n",
        "    test_sentences = sentences[:n_test]\n",
        "    test_ground_truth = ground_truth[:n_test]\n",
        "\n",
        "    print(f\"Testing on {n_test} samples...\")\n",
        "\n",
        "    for i, sentence in enumerate(test_sentences):\n",
        "        if i % 25 == 0:\n",
        "            print(f\"   Progress: {i}/{n_test} ({i/n_test*100:.1f}%)\")\n",
        "\n",
        "        try:\n",
        "            prediction_text = generate_prediction_gradnorm(model, tokenizer, sentence, loading_status)\n",
        "            pred_pairs = parse_prediction_enhanced(prediction_text, loading_status)\n",
        "            predictions.append(pred_pairs)\n",
        "\n",
        "            if i < 3:\n",
        "                print(f\"   Sample {i+1}: {len(pred_pairs)} pairs predicted\")\n",
        "                print(f\"   Raw output: {prediction_text[:100]}...\")\n",
        "                print(f\"   Parsed pairs: {pred_pairs}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"WARNING: Error sample {i}: {e}\")\n",
        "            predictions.append([])\n",
        "\n",
        "    evaluation_time = time.time() - start_time\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(f\"Calculating metrics...\")\n",
        "    exact_metrics = calculate_metrics_exact_match(predictions, test_ground_truth)\n",
        "\n",
        "    # Save results\n",
        "    results[dataset_name] = {\n",
        "        'exact_metrics': exact_metrics,\n",
        "        'evaluation_time': evaluation_time,\n",
        "        'samples_per_second': n_test / evaluation_time,\n",
        "        'predictions': predictions[:5],\n",
        "        'ground_truth': test_ground_truth[:5],\n",
        "        'model_type': loading_status,\n",
        "        'n_samples': n_test,\n",
        "        'base_model': MODEL_BASE\n",
        "    }\n",
        "\n",
        "    print(f\"Evaluation completed in {evaluation_time:.2f}s\")\n",
        "    print(f\"Speed: {n_test/evaluation_time:.2f} samples/sec\")\n",
        "\n",
        "# Step 8: Results Display\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GRADNORM + ORDINAL CONTRASTIVE EVALUATION RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "for dataset_name, result in results.items():\n",
        "    exact_metrics = result['exact_metrics']\n",
        "\n",
        "    print(f\"\\nRESULTS - {dataset_name.upper()}\")\n",
        "    print(f\"Base model: {result['base_model']}\")\n",
        "    print(f\"Model type: {loading_status}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    print(f\"EXACT MATCH METRICS:\")\n",
        "    print(f\"   Exact Match Accuracy:     {exact_metrics['exact_match_accuracy']:.4f} ({exact_metrics['exact_match_accuracy']*100:.2f}%)\")\n",
        "    print(f\"   Exact Precision:          {exact_metrics['exact_precision']:.4f} ({exact_metrics['exact_precision']*100:.2f}%)\")\n",
        "    print(f\"   Exact Recall:             {exact_metrics['exact_recall']:.4f} ({exact_metrics['exact_recall']*100:.2f}%)\")\n",
        "    print(f\"   Exact F1-Score:           {exact_metrics['exact_f1_score']:.4f} ({exact_metrics['exact_f1_score']*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nPERFORMANCE:\")\n",
        "    print(f\"   Evaluation speed:         {result['samples_per_second']:.2f} samples/sec\")\n",
        "\n",
        "# Step 9: Meta-Parameters Analysis\n",
        "if loading_status == \"gradnorm_complete\" and hasattr(model, 'meta_params'):\n",
        "    print(f\"\\n\" + \"=\"*80)\n",
        "    print(\"GRADNORM META-PARAMETERS ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    final_params = model.meta_params.get_meta_params()\n",
        "\n",
        "    print(\"Optimized meta-parameters:\")\n",
        "    print(f\"  lambda_base (contrastive): {final_params['lambda_base'].item():.6f}\")\n",
        "    print(f\"  lambda_ord (ordinal): {final_params['lambda_ord'].item():.6f}\")\n",
        "    print(f\"  T_gen (generation): {final_params['T_gen'].item():.6f}\")\n",
        "    print(f\"  T_ctr (contrastive): {final_params['T_ctr'].item():.6f}\")\n",
        "\n",
        "    print(\"\\nOrdinal configuration:\")\n",
        "    print(f\"  Planning margin: {model.ordinal_contrastive_loss_fn.planning_margin}\")\n",
        "    print(f\"  Base margin: {model.ordinal_contrastive_loss_fn.base_margin}\")\n",
        "\n",
        "    # Balance analysis\n",
        "    lambda_ratio = final_params['lambda_ord'].item() / final_params['lambda_base'].item()\n",
        "    temp_ratio = final_params['T_ctr'].item() / final_params['T_gen'].item()\n",
        "\n",
        "    print(f\"\\nBalance analysis:\")\n",
        "    print(f\"  Ratio lambda_ord/lambda_base: {lambda_ratio:.3f}\")\n",
        "    print(f\"  Ratio T_ctr/T_gen: {temp_ratio:.3f}\")\n",
        "\n",
        "    if lambda_ratio < 0.5:\n",
        "        print(f\"  Note: lambda_ord relatively low - ordinal objective has less impact\")\n",
        "    elif lambda_ratio > 1.5:\n",
        "        print(f\"  Note: lambda_ord relatively high - ordinal objective dominates\")\n",
        "    else:\n",
        "        print(f\"  Note: Good balance between contrastive objectives\")\n",
        "\n",
        "# Step 10: Results Saving\n",
        "print(f\"\\nStep 10: Saving results...\")\n",
        "\n",
        "results_dir = f\"/content/drive/MyDrive/A3CG_GradNorm_Evaluation_Results\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "results_file = f\"{results_dir}/gradnorm_evaluation_results_{timestamp}.json\"\n",
        "\n",
        "save_data = {\n",
        "    'timestamp': timestamp,\n",
        "    'model_info': {\n",
        "        'model_path': model_path,\n",
        "        'base_model': MODEL_BASE,\n",
        "        'loading_status': loading_status,\n",
        "        'architecture_verified': architecture_ok\n",
        "    },\n",
        "    'evaluation_results': results\n",
        "}\n",
        "\n",
        "# Add meta-parameters if available\n",
        "if loading_status == \"gradnorm_complete\" and hasattr(model, 'meta_params'):\n",
        "    final_params = model.meta_params.get_meta_params()\n",
        "    save_data['meta_parameters'] = {\n",
        "        k: v.item() if isinstance(v, torch.Tensor) else v\n",
        "        for k, v in final_params.items()\n",
        "    }\n",
        "\n",
        "# Save\n",
        "with open(results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(save_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Results saved: {results_file}\")\n",
        "\n",
        "# Conclusion\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GRADNORM EVALUATION COMPLETED!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"End time: {time.strftime('%H:%M:%S')}\")\n",
        "print(f\"Model evaluated: {os.path.basename(model_path)}\")\n",
        "print(f\"Status: {loading_status}\")\n",
        "\n",
        "if results:\n",
        "    avg_f1 = np.mean([r['exact_metrics']['exact_f1_score'] for r in results.values()])\n",
        "    print(f\"Average F1-Score: {avg_f1:.4f} ({avg_f1*100:.2f}%)\")\n",
        "\n",
        "print(f\"Results saved in: {results_dir}\")\n",
        "\n",
        "if loading_status == \"gradnorm_complete\":\n",
        "    print(\"SUCCESS: Complete GradNorm model evaluated with meta-parameters!\")\n",
        "elif loading_status == \"contrastive_only\":\n",
        "    print(\"SUCCESS: Contrastive model evaluated (without meta-parameters)\")\n",
        "else:\n",
        "    print(\"WARNING: Only LoRA adapters were evaluated\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "22gwfi1Hamje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}